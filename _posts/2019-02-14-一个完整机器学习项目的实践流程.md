---
layout:     post
title:      一个完整机器学习项目的实践流程
subtitle:   
date:       2019-02-14
author:     Yezhiwei
header-img: img/WechatIMG38.jpeg
catalog: true
category: BigData
tags:
    - BigData
---

### 1 获取语料

已有语料：业务部门、公司积累大量的文本数据
网上下载、抓取语料：可以通过爬虫自己去抓取一些数据，然后进行加工。

### 2 语料预处理

语料预处理大概会占到整个50%-70%的工作量，通过数据洗清、分词、词性标注、去停用词四个大的方面来完成语料的预处理工作。

a.语料清洗：就是在语料中找到我们感兴趣的东西，把不感兴趣的视为噪音的内容清洗删除，如：对于爬取的网页内容，需要去除广告、标签、HTML、JS等代码和注解等。

b.分词：中文语料数据为一批短文本或长文本，如：句子、文章摘要、段落或整篇文章组成的一个集合。一般句子、段落之间的字、词语是连续的，有一定含义。

c.词性标注：就是给每个词或者词语打词类标签，如形容词、动词、名词等。这样做可以让文本在后面的处理中融入更多有用的语言信息。如，常见的文本分类就不用关心词性问题，但是类似情感分析、知识推理却是需要的

d.去停用词：停用词一般指对文本特征没有任何贡献作用的字词，比如标点符号、语气、人称等一些词。所以在一般性的文本处理中，分词之后，接下来一步就是去停用词。但是比如在情感分析中，语气词、感叹号是应该保留的，因为他们对表示语气程度、感情色彩有一定的贡献和意义。

### 3 特征工程

做完语料预处理之后，接下来需要考虑如何把分词之后的字和词语表示成计算机能够计算的类型。把中文分词的字符串转换成数字，有两种常用的表示模型分别是词袋模型和词向量。

词袋模型（Bag of Word, BOW)，即不考虑词语原本在句子中的顺序，统计词频这只是最基本的方式，TF-IDF 是词袋模型的一个经典用法。

词向量是将字、词语转换成向量矩阵的计算模型。目前为止最常用的词表示方法是 One-hot，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。还有 Google 团队的 Word2Vec，其主要包含两个模型：跳字模型（Skip-Gram）和连续词袋模型（Continuous Bag of Words，简称 CBOW），Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。除此之外，还有一些词向量的表示方式，如 Doc2Vec、WordRank 和 FastText 等。

### 4 特征选择

构造好的特征向量，是要选择合适的、表达能力强的特征。文本特征一般都是词语，具有语义信息，使用特征选择能够找出一个特征子集，其仍然可以保留语义信息；但通过特征提取找到的特征子空间，将会丢失部分语义信息。所以特征选择是一个很有挑战的过程，更多的依赖于经验和专业知识，并且有很多现成的算法来进行特征的选择

### 5 模型训练

在特征向量选择好之后，接下来就是训练模型，对于不同的应用需求，我们使用不同的模型，传统的有监督和无监督等机器学习模型， 如 KNN、SVM、Naive Bayes、决策树、GBDT、K-means 等模型；深度学习模型比如 CNN、RNN、LSTM、 Seq2Seq、FastText、TextCNN 等。这些模型在后续的分类、聚类、神经序列、情感分析等示例中都会用到。

在模型训练时需要注意的几个点（之前的每日一问已经涉及到了）：

1.注意过拟合、欠拟合问题，不断提高模型的泛化能力。

2.对于神经网络，注意梯度消失和梯度爆炸问题。

### 6 评价指标

训练好的模型，上线之前要对模型进行必要的评估，目的让模型对语料具备较好的泛化能力。具体有以下这些指标可以参考。

错误率、精度、准确率、精确度、召回率、F1 衡量。

错误率：是分类错误的样本数占样本总数的比例。
精度：是分类正确的样本数占样本总数的比例。
准确率：是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例。
精确度：是分类正确的样本数占样本总数的比例。
召回率：是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。
F1 衡量：表达出对查准率/查全率的不同偏好。

### 7 模型上线应用

模型线上应用，线下训练模型，然后将模型做线上部署，发布成接口服务以供业务系统使用。

### 总结

获取语料——>语料预处理（语料清洗、分词、词性标注、去停用词）——> 特征工程 ——>特征选择——>模型训练 ——>评价指标 ——>模型上线应用